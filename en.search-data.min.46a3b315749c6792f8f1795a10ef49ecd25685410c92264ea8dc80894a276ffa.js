'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href','section'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/MLOS/CODE_OF_CONDUCT/','title':"C O D E O F C O N D U C T",'section':"",'content':"Microsoft Open Source Code of Conduct This project has adopted the Microsoft Open Source Code of Conduct.\nResources:\n Microsoft Open Source Code of Conduct Microsoft Code of Conduct FAQ Contact opencode@microsoft.com with questions or concerns  "});index.add({'id':1,'href':'/MLOS/CONTRIBUTING/','title':"C O N T R I B U T I N G",'section':"",'content':"Contributing to MLOS This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.\nThis project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.\nDetails main is considered the primary development branch.\nWe expect development to follow a typical \u0026ldquo;gitflow\u0026rdquo; style workflow:\n  Fork a copy of the MLOS repo in Github.\n  Create a development (a.k.a. topic) branch off of main to work on changes.\ngit checkout -b YourDevName/some-topic-description main\r  Submit changes for inclusion as a Pull Request on Github.\n  PRs are associated with Github Issues and need MLOS-committers to sign-off (in addition to other CI pipeline checks like tests and lint checks to pass).\n  Once approved, the PR can be completed using a squash merge in order to keep a nice linear history.\n  Caveats There are consumers of MLOS internal to Microsoft that use an internal copy of the Github repo targetting code that is not open-sourced. This arrangement sometimes means porting changes from the internal repo to Github (and vise-versa). When that happens, the changes are submitted as a PR as described above, with the slight modification of (once approved and passing tests) using a rebase based merge instead of a squash merge in order to allow detecting duplicate patches between the public and private repos.\nAdditionally, to try and catch breaking changes we run some extra internal integration tests as well. If they do find issues, we encourage a conversation to occur on how to resolve them in the PRs.\n"});index.add({'id':2,'href':'/MLOS/documentation/01-Prerequisites/','title':"01 Prerequisites",'section':"Documentation",'content':"Prerequisites for building and using MLOS These are one-time setup instructions that should be executed prior to following the build instructions in 02-Build/\nContents  Prerequisites for building and using MLOS  Contents Linux  Linux Requirements Clone the repository Linux Docker Install Install Linux Build Tools  Docker Build Image Manual Build Tools Install   Linux Python Install  Docker Python Install Using Conda Manual Python Install     Windows  Windows Requirements Clone the repository Windows build tools  Using a local script Build Tools Using Chocolatey Windows Build Manually   Windows Python Install  Conda Based Install for Windows Python Using Chocolatey   Windows Docker Install      MLOS currently supports 64-bit Intel/AMD platforms, though ARM64 support is under development. It supports Windows and Linux environments. Below we provide instructions for each OS.\nLinux Linux Requirements  Ubuntu 16.04 (xenial), 18.04 (bionic), 20.04 (focal)   Other distros/versions may work, but are untested.\n Clone the repository Make sure you have git available:\napt-get -y install git Clone the repository:\ngit clone https://github.com/microsoft/MLOS.git Linux Docker Install Docker is used for certain portions of the end-to-end examples and as a convient way to setup the build/dev/test environments.\n If you are starting with the Python only setup, you can skip this step for now if you wish.\n Please see the official Docker install documenation for distribution specific documentation:\n  Ubuntu: https://docs.docker.com/engine/install/ubuntu/\nAs a short guide (copied from the link above):\nsudo apt-get remove \\  docker docker-engine docker.io containerd runc sudo apt-get update sudo apt-get install \\  apt-transport-https ca-certificates curl gnupg-agent software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg \\  | sudo apt-key add - sudo add-apt-repository \\  \u0026#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs)stable\u0026#34; sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io apt-get install docker-ce   Install Linux Build Tools MLOS uses and supports several different languages, so needs their respective build tools installed.\n To focus only on Python to start, skip ahead to the Python Install instructions.\n  The easiest path is probably using the docker image instructions we provide however, if you want to setup the build environment manually use set of instructions below.\n Docker Build Image To automatically setup a Linux build environment using docker, run the following to build the image locally:\n Note: we will eventually publish for use with docker pull instead.\n # Select your target Ubuntu version: UbuntuVersion=20.04 # Build the docker image: docker build --build-arg=UbuntuVersion=$UbuntuVersion -t mlos/build:ubuntu-$UbuntuVersion .  Where UbuntuVersion can also be set to another supported version of Ubuntu.\n  Tip: you can also pass --build-arg=http_proxy=http:/some-proxy-caching-host:3128 to help direct apt and pip to fetch the necessary packages via local caches.\n See 02-Build/ for instructions on how to run this image.\nManual Build Tools Install To manually setup your own Linux build environment:\n# Make sure some basic build tools are available: sudo apt-get install build-essential # Make sure some apt related tools are available: sudo apt-get install \\  apt-transport-https ca-certificates curl gnupg-agent software-properties-common # Make sure an appropriate version of clang is available: ./scripts/install.llvm-clang.sh # Make sure some dotnet dependencies are available: sudo apt-get install liblttng-ctl0 liblttng-ust0 zlib1g libxml2  Note: older distros such as Ubuntu 16.04 may also need the libcurl3 package installed for dotnet restore to work, but is unavailable on (or will break) more recent versions of Ubuntu.\n  Note: libxml2 pulls an appropriate version of libicu.\n  Note: most other dependencies like dotnet and cmake are automatically fetched to the tools/ directory using helpers in scripts/ and invoked by the Makefile and cmake tools.\n Optional tools:\nsudo apt-get install exuberant-ctags  When available make ctags can be invoked to help generate a tags database at the root of the source tree to allow easier code navigation in editors that support it.\n Linux Python Install Docker Python Install If you used the Docker build image instructions you\u0026rsquo;re done! All of the required packages should already be installed in the image.\nUsing Conda TODO\nManual Python Install   Install Python 3.7\n# We need to add a special apt repository for Python 3.7 support: sudo apt-get -y install \\  software-properties-common apt-transport-https sudo add-apt-repository -y ppa:deadsnakes/ppa sudo apt-get update sudo apt-get -y install python3.7   Install MLOS Python dependencies:\n# Also add some dependencies needed by some of the pip modules sudo apt-get -y install python3-pip python3.7-dev \\  build-essential libfreetype-dev unixodbc-dev python3.7 -m pip install --upgrade pip python3.7 -m pip install setuptools python3.7 -m pip install \\  -r source/Mlos.Python/requirements.txt   Windows  Note: Most Windows shell commands here expect powershell (or pwsh).\n Windows Requirements  Portions of MLOS use Docker, which requires a Linux VM. So support for one of the following is required:\n  WSL2, or Hyper-V support   Note: WSL2 is advised for ease of setup, integrations with Docker, and more flexible resource utilizations benefits.\n See the Install Docker section for more details.\nClone the repository Cross platform\ngit clone https://github.com/microsoft/MLOS.git  See https://git-scm.com/book/en/v2/Getting-Started-Installing for help installing git, or use choco install git (see below for more details about chocolatey).\n Windows build tools There are several build tools install paths to choose from on Windows.\n Note: For most of these commands we first need a powershell with Administrator privileges:\n   Start a powershell environment with Administrator privileges:\npowershell -NoProfile -Command \u0026#34;Start-Process powershell -Verb RunAs\u0026#34;  If you find that when you start a new shell environment it can\u0026rsquo;t find some of the tools installed later on, the new PATH environment variable might not be updated. Try to restart your machine.\n   Allow local powershell scripts to be executed:\nSet-ExecutionPolicy RemoteSigned -Scope CurrentUser -Force  This is necessary for our build environment initialization script scripts\\init.windows.ps1 as well.\n   Using a local script   Launch the script we provide in the MLOS repo to install/update the free Visual Studio 2019 Community Edition with the necessary components:\n.\\scripts\\install-vs2019.ps1 Waiting for installer process vs_community to end ... Waiting for installer process vs_community to end ... ... Done  Note: This will install the free Community edition by default. Use the -Sku option if you prefer to install the Enterprise version instead.\n   Build Tools Using Chocolatey Chocolatey is a package manager for Windows to help support scripted and reproducable installation of tools.\n Install chocolatey:\nSet-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString(\u0026#39;https://chocolatey.org/install.ps1\u0026#39;)) Getting latest version of the Chocolatey package for download. ... Chocolatey (choco.exe) is now ready. You can call choco from anywhere, command line or powershell by typing choco. Run choco /? for a list of functions. You may need to shut down and restart powershell and/or consoles first prior to using choco. ... See Also: https://chocolatey.org/install\n  Install build tools:\nchoco install -y git choco install -y dotnetcore-runtime.install --params=\u0026#34;Skip32Bit\u0026#34; choco install -y dotnetcore dotnetcore-sdk choco install -y visualstudio2019buildtools visualstudio2019-workload-netcorebuildtools visualstudio2019-workload-vctools   Install an editor (optional)\nchoco install -y vscode choco install -y vscode-cpptools vscode-csharp vscode-cake or\nchoco install -y visualstudio2019community   Windows Build Manually Download and install Visual Studio 2019 (free) Community Edition:\nhttps://visualstudio.microsoft.com/vs/community/\nBe sure to include support for .Net Core and C++.\nWindows Python Install Conda Based Install for Windows TODO\nPython Using Chocolatey  See above for instructions on installing Chocolatey.\n  Install Python\nchoco install -y python --version=3.7.8   Install MLOS Python dependencies:\npip install -r source\\Mlos.Python\\requirements.txt   Windows Docker Install As mentioned above, Docker on Windows first requires a Linux VM.\n As such, if your Windows development environment is itself a VM, you\u0026rsquo;ll need one that supports nested virtualization.\nhttps://docs.microsoft.com/en-us/azure/virtual-machines/acu\n   The easiest route is through WSL2:\n  Enable WSL2 on Windows 10 build 2004 or later:\ndism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart Invoke-WebRequest -Uri https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi -OutFile wsl_update_x64.msi -UseBasicParsing Invoke-Item wsl_update_x64.msi  Note: You may need to restart at this point.\n wsl --set-default-version 2   Install a Linux distro for WSL2 (e.g. Ubuntu 20.04):\nInvoke-WebRequest -Uri https://aka.ms/wslubuntu2004 -OutFile Ubuntu-20.04.appx -UseBasicParsing Add-AppxPackage ./Ubuntu-20.04.appx  Finish the installation by launching the \u0026ldquo;Ubuntu 20.04\u0026rdquo; distribution from the Start menu to setup your Linux account in the WSL distribution.\n   Install Docker\n  Chocolatey\nchoco install docker-desktop docker-cli   Manually\nhttps://docs.docker.com/docker-for-windows/install/\n  Configure Docker Desktop to use WSL2\n  At this point docker commands should work naturally from any shell environment and proxied through to the WSL2 Linux distribution configured in Docker Desktop.\n  Alternatively, you can enable Hyper-V and use docker-machine to create a VM suitable for running Docker containers:\n Note: This isn\u0026rsquo;t supported on Windows Home edition.\n   Enable Hyper-V\nEnable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V -All   Install docker-machine:\n  Manually:\nhttps://docs.docker.com/machine/install-machine/\n  Or, via Chocolatey:\nchoco install docker-machine     Build a VM for running Docker containers:\ndocker-machine create --driver hyperv --hyperv-virtual-switch \u0026#34;NameOfYourDockerVSwitch\u0026#34; docker-dev-vm   Invoke a shell environment to use it:\ndocker-machine env --shell powershell docker-dev-vm | Invoke-Expression From within this shell environment, docker cli commands should be proxied through to your docker-dev-vm prepared by docker-machine.\n    "});index.add({'id':3,'href':'/MLOS/documentation/02-Build/','title':"02 Build",'section':"Documentation",'content':"Build Instructions for MLOS Prerequisites See 01-Prerequisites/ for initial build tools setup instructions.\nThere are different instructions according to the environment setup you chose.\nContents  Build Instructions for MLOS  Prerequisites Contents Docker Linux  CLI VSCode   Windows  CLI Visual Studio      Docker If you chose to use the Docker build environment and have already built or pulled a container image using the instructions in 01-Prerequisites/ you can start an interactive session using the container image as follows:\n# Using the UbuntuVersion local shell variable set earlier to \u0026#34;docker build\u0026#34; the image:\rUbuntuVersion=20.04\r# Run the image:\rdocker run -it -v $PWD:/src/MLOS \\\r --name mlos-build-$UbuntuVersion \\\r mlos/build:ubuntu-$UbuntuVersion\r The -v $PWD:/src/MLOS option makes the current directory (assumed to be the root of the MLOS repository) available inside the container so that you can edit the code from your host machine, but build it inside the container.\n  Note that the build artifacts located at out/ in the container are kept separate by default, so you can test with multiple containers at a time. You can use additional -v /path/to/out-$UbuntuVersion:/src/MLOS/out style arguments to direct that output to a host accessible locations if desired.\n # Start the image if it already exists and was stopped:\rdocker start -i mlos-build-$UbuntuVersion\r# Start a new shell session inside the image:\rdocker exec -it mlos-build-$UbuntuVersion /bin/bash\rOnce you have an interactive session in the container, the MLOS source code is available at /src/MLOS and can be built using the same instructions in the Linux CLI section below.\nLinux CLI We provide Makefile wrappers to invoke the language specific build systems.\nmake\r This is equivalent to make dotnet-build cmake-build\n If you want to switch to a debug build run:\nexport CONFIGURATION=Debug\rmake\r Note: export CONFIGURATION=Release to switch back to Release builds.\n The Makefiles in most source folders are simply wrappers around the cmake build system and allow easier interactive building during development without having to maintain shell environment variables or additional paths.\nIn general cmake is used for C++ projects, with simple CMakeLists.txt wrappers around dotnet build for their C# dependencies to do code generation.\nIn top-level directories you can restrict the build to just dotnet wrappers or just cmake wrappers like so:\nmake dotnet-build\rmake dotnet-test\rmake dotnet-clean\rmake cmake-build\rmake cmake-test\rmake cmake-clean\r Note: A similar shell environment setup can optionally be obtained with the following\nsource ./scripts/init.linux.sh\r To build and run the tests below the current directory run\nmake check\r This is equivalent to make all test\n VSCode TODO: Provide some notes about how cmake and dotnet integration works with vscode.\nWindows For the C++ and C# project components, Visual Studio msbuild can be used on Windows systems.\n Note: Visual Studio build tools are available free.\nPlease see the initial setup instructions linked above for details.\n CLI Visual Studio build tools need to be added to the shell environment.\n  Setup the powershell environment to find the Visual Studio build tools.\n.\\scripts\\init.windows.ps1\r Note: you can also execute .\\scripts\\init.windows.cmd if you prefer a cmd environment.\n   Use msbuild to build the project file in the current directory.\n e.g. when run from the root of the MLOS repo this will recursively build all the projects and run the tests.\n msbuild /m /r /p:Configuration=Release\rSome additional build flags to help provide additional control over the process:\n /m runs a multi-process parallel build process /r is required on first build and git pull to restore any nuget packages required \\ /fl will optionally produce a msbuild.log file /p:Configuration=Release will perform a non-debug build.  Note: If omitted, msbuild will produce a Debug build by default. Debug builds perform no compiler optimizations, so are useful for troubleshooting, but will be more difficult for MLOS to help optimize.\n  /p:RunUnitTest=false will temporarily skip running unit tests /p:StyleCopEnabled=false will temporarily skip C# style checks /p:UncrustifyEnabled=false will temporarily skip C++ style checks /p:BuildProjectReferences=false will temporarily only build the current project file, and skip rebuilding its dependencies (note: this option doesn\u0026rsquo;t work when building .sln files)    Visual Studio  Note: Visual Studio 2019 Community Edition is available free.\nPlease see the initial setup instructions linked above for details.\n Opening a *.sln file in the source/ directory with Visual Studio 2019 should allow you to build inside the IDE.\n  Setup the shell environment to find the devenv script provided by Visual Studio.\n.\\scripts\\init.windows.ps1\r Note: you can also execute .\\scripts\\init.windows.cmd if you prefer a cmd environment.\n   Launch Visual Studio for a given solution:\ndevenv MLOS.NetCore.sln\rAlternatively, you can launch devenv for a project and manually add its dependencies to the solution that Visual Studio creates. For instance:\ndevenv MLOS.Core.vcxproj\r  "});index.add({'id':4,'href':'/MLOS/documentation/03-ExampleUsage/','title':"03 Example Usage",'section':"Documentation",'content':"Examples of using MLOS to optimize a system TODO\n"});index.add({'id':5,'href':'/MLOS/documentation/04-Test/','title':"04 Test",'section':"Documentation",'content':"Test Instructions for MLOS TODO: document how to run unit tests for\n C++ C#  Python First, ensure that the necessary Python modules are installed. See 01-Prerequisites/ for details.\nLinux scripts/run-python-tests.sh Windows scripts\\run-python-tests.cmd "});index.add({'id':6,'href':'/MLOS/documentation/05-Debug/','title':"05 Debug",'section':"Documentation",'content':"TODO\n"});index.add({'id':7,'href':'/MLOS/documentation/','title':"Documentation",'section':"",'content':"MLOS Documentation This directory contains project wide documentation for things like coding standards, overall architecture descriptions, build instructions, etc.\nIndividual components may also include their own more detailed documentation within their subdirectories.\n Note: Some documentation uses Mermaid for diagrams in addition to Markdown.\nYou can install Markdown Preview Enhanced for Atom or Visual Code to help render it more easily.\n Getting Started Here\u0026rsquo;s a brief summary of some documentation suggestions to help get started:\n See 01-Prerequisites/ for initial environment setup instructions. See 02-Build/ for basic build instructions. See 03-ExampleUsage/ for some usage examples for applying MLOS to some code/system. See 04-Test/ for notes on testing those changes. See 05-Debug/ for notes on debugging those changes.  Overview Here\u0026rsquo;s some documentation references describing the MLOS architecture:\n MlosArchitecture/ Glossary/ DEEM 2020 Paper  Here\u0026rsquo;s a document describing the layout of the repository:\n RepoOrganization/  Contributing See CONTRIBUTING/ for notes on making changes to MLOS itself.\n"});index.add({'id':8,'href':'/MLOS/documentation/CodingStandard/','title':"Coding Standard",'section':"Documentation",'content':"MLOS Coding Standards MLOS uses and supports multiple languages. Here we document the coding styles and standards we attempt to adhere to and the tools we use to achieve that.\nC++ For C++ we mostly try to follow the Google C++ style guidelines, with a few modifications.\nCurrently we rely on uncrustify to help enforce these rules (plus a little bit of human review).\nSee build/uncrustify/README/ for additional information.\nThough we attempt to make it somewhat readable, we exclude code generated by MLOS from these strict style checks.\nuncrustify is invoked as a part of the build process (see 02-Build/ for details on temporarily disabling it locally).\nC# We use StyleCopAnalyzers to mostly follow the standard recommended C# style guidelines, with a few exceptions listed in build/MLOS.NetCore.ruleset.\nThough we attempt to make it somewhat readable, we exclude code generated by MLOS from these strict style checks using an \u0026lt;auto-generated /\u0026gt; tag file header.\nStyleCop is invoked as a part of the build process (see 02-Build/ for details on temporarily disabling it locally).\nPython We use pylint for Python code to mostly follow PEP 8 guidelines. Its configuration can be found at source/.pylintrc.\nTo run it locally, issues the following commands:\n  One time install of the pylint tool:\npip install pylint\r  Followed by:\n  Linux:\nscripts/run-python-checks.sh\r  Windows:\nscripts\\run-python-checks.cmd\r    We also use licenseheaders to add ensure license headers are added to .py files.\nTo run it locally, issues the following commands:\n  One time install of the licenseheaders tool:\npip install licenseheaders\r  Followed by:\n  Linux:\nscripts/update-python-license-headers.sh\r  Windows:\nscripts\\update-python-license-headers.cmd\r     Note: Currently this has issues with conflicting cross-platform line-ending styles.\nUse git diff --ignore-cr-at-eol to identify the differences.\n "});index.add({'id':9,'href':'/MLOS/documentation/Glossary/','title':"Glossary",'section':"Documentation",'content':"MLOS Terms Glossary TODO\n"});index.add({'id':10,'href':'/MLOS/documentation/MlosArchitecture/','title':"Mlos Architecture",'section':"Documentation",'content':"MLOS Architecture This document provides a brief overview of the MLOS architecture for supporting Machine Learning Optimized Systems.\n MLOS Architecture  High Level Description  Principles Workflows   Architecture Diagram  Main Components Shared Memory Regions Target process  Mlos.Core Shared Channel   Mlos.Agent  Mlos.NetCore Settings Registry Assemblies Grpc Server Experiment Management     Implementation Details    High Level Description At a high level, MLOS provides infrastructure to support instance-specific tuning systems software (e.g. written in C++) in a trackable and reproducible way.\nMLOS does this by focusing on optimizing tunables that exist in code.\nTunables can take several forms:\n Build time  e.g. inlined constants controlling buffer size or hash function, choice of concrete ADT implementation, etc.   Startup  e.g. configurations that can only be changed with a process restart   Runtime  e.g. dynamic settings that can changed between instantiations, queries, or other events. Some of these may be known at compile-time, while others may only be known at runtime for a specific instance (e.g. number of tables in a database schema).    To optimize these tunables, the system needs to be observable. In other words, it needs to provide additional data (e.g. workload, telemetry, metrics, etc.) about the its operation. When combined additional information obtained from the system executing the process (e.g. OS/HW metrics), we call this combined set of information the context.\nPrinciples   Separation\nTo support lightweight observable components with minimal impact on the target system\u0026rsquo;s performance, we separate the data aggregation and optimization steps to a (local) external agent process. It communicates with the target system using shared memory channels for low latency.\n  Segmentation\nTo support faster iteration, we allow focusing build-time constant tuning to specific components of the target system using micro benchmarks.\n  Workflows MLOS workflows take roughly two basic forms:\n  Build-time optimization\nMicrobenchmarks develepers write for smart components can be used to explore component tunable parameter values either interactively or in the background (e.g. during continuous integration pipelines).\nThe data collected from those \u0026ldquo;experiments\u0026rdquo; can be captured and explored in Notebook experiences that can then be checked back in with the resulting code change to help support reproducible tests to validate these parameters in the future.\nSince these tunables may affect many instances, optimization goals here may focus on robustness in addition to performance or some other metric.\n  Runtime optimization\nSmart components can be hooked up to receive suggestions from the external agent during runtime for online instance specific optimizations as well.\n  Architecture Diagram Main components   Target process\nThis is the MLOS enabled system to tune (e.g. an end-to-end system like SqlServer or Smart micro benchmarks for a component, etc.). The process contains tunable \u0026ldquo;Smart\u0026rdquo; components that are made observable by the Mlos.Agent by exporting telemetry/metrics over Shared memory channels and are optimized using Mlos.Optimizer.Service suggestions.\n  Mlos.Agent\nThe primary responsibility of the Mlos.Agent is to observe the target process and manage the \u0026ldquo;experiments\u0026rdquo;. The experiments define the aggregates from the telemetry stream and exchange it with Mlos.Optimizer.Service.\n  Mlos.Client\nThe Mlos.Client is a utility application that allows us to query the state of shared components and create new experiments.\n  Shared memory\nShared memory regions are used to exchange messages and share the configuration objects between the Target process and the Mlos.Agent.\n  Mlos.Optimizer.Service\nMlos.Optimizer.Service is a Docker instance containing the Mlos.Optimizer and an RDBMS instance (e.g. SqlServer) for storing experiment data, optimizer models, etc.\nTo exchange the messages between Mlos.Agent experiments and Mlos.Optimizers, the database is currently used as a transport channel.\n  Shared Memory Regions   Global Shared Memory\nThe primary shared memory entry point. It used to bootstrap and contains metadata about all other memory regions. It also includes shared channel synchronization objects.\n  Config Shared Memory\nWe store all components\u0026rsquo; configuration in the config shared memory region. Configuration objects are accessible from the Target process and from Mlos.Agent.\n  Control/Telemetry Channel Shared Memory\nMemory region used (exclusively, no header) to exchange messages from the Target process to Mlos.Agent.\n  Feedback Channel Shared Memory\nA memory region used (exclusively, no header) to exchange messages from Mlos.Agent to Target process.\n  Some memory regions contain a header block that helps with their identification. The exceptions are shared channel memory regions, where the channel uses all memory. Control and Feedback Channels are circular buffers whose size must be a power of two (2N). Prepending a header would prevent proper alignment which is why all communication channel metadata and synchronization objects are located in the Global Shared Memory region.\nSee Also: SharedChannel/ for more details about their implementation.\nTarget Process Mlos.Core Mlos.Core is a (C++) library used inside the target process. It provides an API to handle shared configs and exchange messages with Mlos.Agent via a shared channel.\nMlos.Core contains the following components:\n  MlosContext\nA class responsible for managing shared memory channels. It provides methods for sending telemetry and control messages to the Mlos.Agent as well as receiving feedback messages from it.\n  SharedConfigManager\nA class responsible for managing shared configs. It allows for registering configs in shared memory.\n  Shared Channel  Control Channel Feedback Channel  Mlos.Agent Mlos.NetCore Settings registry assemblies Grpc Server Experiment management Implementation details Shared Memory Channel\n"});index.add({'id':11,'href':'/MLOS/documentation/RepoOrganization/','title':"Repo Organization",'section':"Documentation",'content':"Repo Organization Some notes on the directory layout organization in this repo.\n There are build files (e.g. dirs.proj for msbuild or dotnet build, or Makefiles for make) in most directories to allow easy recursive building of that subtree you happen to be in.  Note: we provide Makefile wrappers in most directories to simply help invoke cmake and the Makefiles it generates\n  build/ contains configuration related to building MLOS components  For instance, .props and .targets files for definining and controlling common msbuild and dotnet build properites and targets are contained there, as are various style check configurations.   Note: For this reason, cmake output is redirected to out/cmake/{Release,Debug}/ instead.\n  source/ contains a directory for each component of MLOS, including unit test source code.  i.e. running msbuild or make in the source/ directory will build (and generally analyze) all of the projects, but not execute their tests. source/Examples/ contains sample target codes to optimize with the other MLOS components and help describe the integration methods   test/ contains a directory and project to invoke each of the unit tests.  i.e. running msbuild or make in the test/ directory will also run all of the tests.   scripts/ contains some helper scripts to initialize development environments, install tools, invoke build pipelines, etc.  Auto generated content:\n out/ contains most of the intermediate build output, especially for msbuild and dotnet build portions  out/dotnet contains the msbuild and dotnet build outputs (for Windows) out/Mlos.CodeGen.out contains code generation output from each SettingsRegistry project, organized by originating source/ project directory out/Grpc.out contains the output for the grpc messages between the Mlos.Agents   target/ contains final binaries and libraries produced by msbuild that are suitable for execution out/cmake/ contains most of the output from cmake  Note: this is by convention. Though we provide some configurations to help use this path, other tools or IDEs may override it.\n  tools/ is created for items the cake build scripts may fetch  "});index.add({'id':12,'href':'/MLOS/notebooks/BayesianOptimization/','title':"Bayesian Optimization",'section':"Notebooks",'content':"Download BayesianOptimization.ipynb notebook import matplotlib.pyplot as plt import numpy as np import pandas as pd Bayesian Optimization This notebook demonstrates the basic principles of Bayesian Optimization (BO) and how to use MLOS to perform BO.\nMotivation In software performance engineering, the impact different (input) parameters (e.g. buffer size, worker thread count, etc.) can have on the (output) performance of a system for a given workload (input) can be modeled as a multidimensional function - one which we don\u0026rsquo;t know the equation for apriori, but are instead trying to learn through careful sampling of the input space and experimentation (test/benchmark runs) to gather output points. Bayesian optimization is one technique for efficiently selecting the samples in the input space to learn the approximate shape of that function and find its optimum, i.,e. the parameters that lead to the best performance. In this example we use a synthetic (i.e. made-up) function that we can look at directly to stand in for a complex system with unknown characteristics.\nBayesian Optimization is a global optimization strategy, so a way to find the global optimum of a mathematical function that\u0026rsquo;s not necessarily convex. BO is a black-box optimization technique, meaning that it requires only function values and no other information like gradients.\nThis is in contrast to other optimization strategies, such as gradient descent or conjugate gradient that require gradients and are only guaranteed to find a local optimum (if the function is assumed to be convex, this is also the global optimum).\nFinding the global optimum of a general non-convex function is NP-hard, which makes it impossible to provide effective convergence guarantees for any global optimization strategy, including Bayesian Optimization. However, BO has been found to be quite effective in the past.\nA synthetic example Let\u0026rsquo;s take a simple synthetic example of a one-dimensional function that we assume is unknown. If we actually had access to the function, we could use more efficient techniques using calculus and would not be using Bayesian Optimization.\n# define fake performance function # In an actual application, we would not have access to this function directly. # Instead, we could only measure the outcome by running an experiment, such as timing # a particular run of the system. def f(x): return (6*x-2)**2*np.sin(12*x-4) In a real use case for global optimization, the function we want to optimize is usually only implicitly defined and very expensive to compute, such as training and evaluating a neural network, or timing the run of a large workload on a distributed database. Given the cost of evaluating the function, our goal is to find an optimum while keeping the number of function evaluations to a minimum.\nIn this synthetic example, we actually know the function, so we can just plot it for illustration purposes:\n# define a domain to evaluate line = np.linspace(0, 1) # evaluate function values = f(line) # plot function plt.plot(line, values) plt.xlabel(\u0026#34;Input (parameter)\u0026#34;) plt.ylabel(\u0026#34;Objective (i.e. performance)\u0026#34;) Our goal here is to find the global minimum of this function, assuming that we don\u0026rsquo;t have direct access to the formula (given the formula, we could instead calculate the optimum quite precicely using methods from calculus instead). Usually, the function is too expensive to evaluate in such a manner, in particular in higher-dimensional spaces.\nNow, we use MLOS to construct an OptimizationProblem object that will encapsulate the function and the input space.\nfrom mlos.Optimizers.OptimizationProblem import OptimizationProblem, Objective from mlos.Optimizers.BayesianOptimizer import BayesianOptimizer from mlos.Spaces import SimpleHypergrid, ContinuousDimension # single continuous input dimension between 0 and 1 input_space = SimpleHypergrid(name=\u0026#34;input\u0026#34;, dimensions=[ContinuousDimension(name=\u0026#34;x\u0026#34;, min=0, max=1)]) # define output space, we might not know the exact ranges output_space = SimpleHypergrid(name=\u0026#34;objective\u0026#34;, dimensions=[ContinuousDimension(name=\u0026#34;function_value\u0026#34;, min=-10, max=10)]) # define optimization problem with input and output space and objective optimization_problem = OptimizationProblem( parameter_space=input_space, objective_space=output_space, # we want to minimize the function objectives=[Objective(name=\u0026#34;function_value\u0026#34;, minimize=True)] ) The way Bayesian Optimization (in particular what is known as sequential model-based optimization) works is by iterating the following steps:\n Evaluate the function at a candidate point x_i (start with a random point x_0), observe f(x_i). Build / update a surrogate model g_i of the objective function (here a Random Forest) using the pairs x_i, f(x_i) that we observed so far. Pick the next data point to evaluate based on the updated model g_i using a criterion known as acquisition function.  The idea is that eventually the surrogate model will provide a good approximation of the objective function, but it will be much faster to evaluate (i.e. by predicting with a Random Forest or Gaussian process or another trained machine learning model, instead of running a complex deployment). The acquisition function serves as a means to trade off exploration vs exploitation in collecting new data for building the surrogate model: it picks points that have a low (close to optimum) value of the surrogate model (and so are expected to have a low value of the actual objective). This is the \u0026ldquo;exploitation\u0026rdquo; of existing knowledge in the model. On the other hand, it also encourages exploring new areas in which there is a lot of uncertainty in the surrogate model, i.e. where we expect the surrogate model not to be very acurate yet.\nThis process is coordinated by the BayesianOptimizer object, which we will use to perform Bayesian Optimization with a random forest surrogate model. Details of this particular method can be found in Hutter et. al. (2011). We\u0026rsquo;re first configuring the model to refit after every iteration and use 10 trees for the random forest:\nfrom mlos.Optimizers.BayesianOptimizer import BayesianOptimizer, BayesianOptimizerConfig from mlos.Optimizers.RegressionModels.HomogeneousRandomForestRegressionModel import HomogeneousRandomForestRegressionModelConfig from mlos.Spaces import Point optimizer_config = BayesianOptimizerConfig.DEFAULT.copy() optimizer_config.experiment_designer_config_fraction_random_suggestions = .1 random_forest_config = optimizer_config.homogeneous_random_forest_regression_model_config random_forest_config.decision_tree_regression_model_config.n_new_samples_before_refit = 1 random_forest_config.decision_tree_regression_model_config.splitter = \u0026#39;best\u0026#39; # right now we\u0026#39;re sampling without replacement so we need to subsample to make the trees different when using the \u0026#39;best\u0026#39; splitter random_forest_config.samples_fraction_per_estimator = .9 random_forest_config.n_estimators = 10 optimizer_config.experiment_designer_config.confidence_bound_utility_function_config.alpha = 0.1 optimizer = BayesianOptimizer(optimization_problem, optimizer_config) Now, we can run the actual optimization which will carry out the steps outlined above.\ndef run_optimization(optimizer): # suggest new value from optimizer suggested_value = optimizer.suggest() input_values_df = suggested_value.to_dataframe() # suggested value are dictionary-like, keys are input space parameter names # evaluate target function target_value = f(suggested_value[\u0026#39;x\u0026#39;]) print(suggested_value, target_value) # build dataframes to  target_values_df = pd.DataFrame({\u0026#39;function_value\u0026#39;: [target_value]}) optimizer.register(input_values_df, target_values_df) # run for some iterations n_iterations = 15 for i in range(n_iterations): run_optimization(optimizer) After 15 iterations, the model is likely to have captured the general shape, but probably not have found the actual optimum:\n# evaluate the surrogate surrogate_predictions = optimizer.predict(pd.DataFrame({\u0026#39;x\u0026#39;: line})).get_dataframe() # plot observations feature_values, target_values = optimizer.get_experiment_data() plt.scatter(feature_values, target_values, label=\u0026#39;observed points\u0026#39;) plt.colorbar() # plot true function (usually unknown) plt.plot(line, values, label=\u0026#39;true function\u0026#39;) # plot the surrogate std = np.sqrt(surrogate_predictions[\u0026#39;predicted_value_variance\u0026#39;]) value = surrogate_predictions[\u0026#39;predicted_value\u0026#39;] plt.plot(line, value, label=\u0026#39;surrogate predictions g\u0026#39;) plt.fill_between(line, value - std, value + std, alpha=.1) plt.plot(line, -optimizer.experiment_designer.utility_function(pd.DataFrame({\u0026#39;x\u0026#39;: line})), \u0026#39;:\u0026#39;, label=\u0026#39;utility_function\u0026#39;) plt.ylabel(\u0026#34;Objective function f (performance)\u0026#34;) plt.xlabel(\u0026#34;Input variable\u0026#34;) plt.legend() We can run more iterations to improve the surrogate model and the optimum that is found:\n# run for more iterations n_iterations = 50 for i in range(n_iterations): run_optimization(optimizer) We can now visualize the surrogate model and optimization process again. The points are colored according to the iteration number, with dark blue points being early in the process and yellow points being later. You can see that at the end of the optimization, the points start to cluster around the optimum.\n# evaluate the surrogate surrogate_predictions = optimizer.predict(pd.DataFrame({\u0026#39;x\u0026#39;: line})).get_dataframe() # plot observations feature_values, target_values = optimizer.get_experiment_data() plt.scatter(feature_values, target_values, label=\u0026#39;observed points\u0026#39;) # plot true function (usually unknown) plt.plot(line, values, label=\u0026#39;true function\u0026#39;) # plot the surrogate std = np.sqrt(surrogate_predictions[\u0026#39;predicted_value_variance\u0026#39;]) value = surrogate_predictions[\u0026#39;predicted_value\u0026#39;] plt.plot(line, value, label=\u0026#39;surrogate predictions g\u0026#39;) plt.fill_between(line, value - std, value + std, alpha=.1) plt.plot(line, -optimizer.experiment_designer.utility_function(pd.DataFrame({\u0026#39;x\u0026#39;: line})), \u0026#39;:\u0026#39;, label=\u0026#39;utility_function\u0026#39;) ax = plt.gca() ax.set_ylabel(\u0026#34;Objective function f\u0026#34;) ax.set_xlabel(\u0026#34;Input variable\u0026#34;) bins_axes = ax.twinx() bins_axes.set_ylabel(\u0026#34;Points sampled\u0026#34;) feature_values.hist(bins=20, ax=bins_axes, alpha=.3, color=\u0026#39;k\u0026#39;, label=\u0026#34;count of querry points\u0026#34;) plt.legend() Going further:   Plot the optimum as a function of iterations. How long does it take for the optimization to converge? Is that stable over several random restarts?\n  Does changing the search to a purely random search (setting optimizer_config.experiment_designer_config_fraction_random_suggestions = 1) change how long the optimization takes to find the optimum?\n  Download BayesianOptimization.ipynb notebook "});index.add({'id':13,'href':'/MLOS/notebooks/SmartCacheCppDocker/','title':"Smart Cache Cpp Docker",'section':"Notebooks",'content':"Download SmartCacheCppDocker.ipynb notebook Objective The goal of this notebook is to guide you through the process of executing an optimization process in Mlos.\nSteps  Select build configuration. Generate the secrets file. Build the docker image. Launch the docker container. Launch Mlos.Agent. Launch SmartCache.exe benchmark.  Prerequisites  Build the Mlos project. The build configuration (Debug vs. Retail) must match your choice below. Have Docker installed and available. This notebook is run with {MLOS_ROOT}\\source\\Mlos.Notebooks as a working directory (default if you open from ADS or VS Code).  import json import os import subprocess import time from utils import generate_random_password, build_docker_image, run_docker_container, stop_docker_container, remove_docker_container mlos_root_directory = os.path.abspath(os.path.join(os.getcwd(), \u0026#34;../..\u0026#34;)) Select build configuration ATTENTION: Optimization of DEBUG builds is pointless. Select DEBUG only if you are trying to debug these projects.\nbuild_configuration = \u0026#39;Release\u0026#39; # you can change it to \u0026#39;Debug\u0026#39; here. assert build_configuration in (\u0026#39;Release\u0026#39;, \u0026#39;Debug\u0026#39;) if build_configuration == \u0026#39;Release\u0026#39;: obj_dir = \u0026#34;obj\u0026#34; else: obj_dir = \u0026#34;objd\u0026#34; mlos_agent_server_exe_path = os.path.abspath(os.path.join(mlos_root_directory, \u0026#34;out/dotnet/source/Mlos.Agent.Server\u0026#34;, obj_dir, \u0026#34;AnyCPU\u0026#34;, \u0026#34;Mlos.Agent.Server.exe\u0026#34;)) smart_cache_exe_path = os.path.abspath(os.path.join(mlos_root_directory, \u0026#34;out/dotnet/source/Examples/SmartCache\u0026#34;, obj_dir, \u0026#34;x64\u0026#34;, \u0026#34;SmartCache.exe\u0026#34;)) if not (os.path.exists(mlos_agent_server_exe_path) and os.path.exists(smart_cache_exe_path)): print(f\u0026#34;Are you sure you have done a build in a {build_configuration} configuration?\u0026#34;) Generate the secrets file  Note: We are moving away from using SqlRPC and towards gRPC for communication between Mlos.Agent and the Optimizer Service. However, until that migration is complete, Mlos.Agent has to know how to connect to Sql Server.\n The secrets file is a simple json file generated by the code cell below.\noverwrite_secrets = False secrets_file_path = os.path.abspath(os.path.join(mlos_root_directory, \u0026#34;source/Mlos.Python/Secrets/local_docker_connection_string.json\u0026#34;)) if os.path.exists(secrets_file_path) and not overwrite_secrets: # Secrets already exist. We need to grab the password for later use. # print(f\u0026#34;Secrets file {secrets_file_path} already exists.\u0026#34;) with open(secrets_file_path, \u0026#39;r\u0026#39;) as in_file: secrets = json.load(in_file) sa_password = secrets[\u0026#39;Password\u0026#39;] else: # We need to create the secrets file from the template. sa_password = generate_random_password() sample_secrets_file_path = os.path.abspath(os.path.join(mlos_root_directory, \u0026#34;source/Mlos.Python/Secrets/sample_docker_connection_string.json\u0026#34;)) with open(sample_secrets_file_path, \u0026#39;r\u0026#39;) as in_file: secrets_dict = json.load(in_file) secrets_dict[\u0026#39;Password\u0026#39;] = sa_password with open(secrets_file_path, \u0026#39;w\u0026#39;) as out_file: json.dump(secrets_dict, out_file, indent=2) print(f\u0026#34;Wrote a new secrets file to {secrets_file_path}.\u0026#34;) Secrets file c:\\Users\\bpkroth\\src\\MLOS\\MLOS.msdata.2\\source\\Mlos.Python\\Secrets\\local_docker_connection_string.json already exists.  Build Docker image The optimizer lives inside the Docker. Let\u0026rsquo;s build the image.\nbuild_docker_image(sa_password) Step 1/15 : FROM microsoft/mssql-server-linux:latest ---\u0026gt; 314918ddaedf Step 2/15 : RUN apt-get -y update \u0026amp;\u0026amp; apt-get install -y software-properties-common \u0026amp;\u0026amp; add-apt-repository -y ppa:deadsnakes/ppa \u0026amp;\u0026amp; apt-get -y update \u0026amp;\u0026amp; apt-get install -y python3.7 python3-pip \u0026amp;\u0026amp; apt-get install -y build-essential libssl-dev libffi-dev python3-dev python3.7-dev unixodbc-dev \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* ---\u0026gt; Using cache ---\u0026gt; c96a7f675e7e Step 3/15 : RUN python3.7 -m pip install pip ---\u0026gt; Using cache ---\u0026gt; feb04a146619 Step 4/15 : RUN python3.7 -m pip install --upgrade pip ---\u0026gt; Using cache ---\u0026gt; 199aa4fecd21 Step 5/15 : RUN mkdir -p /usr/src/Mlos.Python ---\u0026gt; Using cache ---\u0026gt; 75325321633c Step 6/15 : WORKDIR /usr/src/ ---\u0026gt; Using cache ---\u0026gt; c28de51505c5 Step 7/15 : COPY ./requirements.txt ./Mlos.Python/requirements.txt ---\u0026gt; Using cache ---\u0026gt; 9e4576c57340 Step 8/15 : RUN python3.7 -m pip install -r /usr/src/Mlos.Python/requirements.txt ---\u0026gt; Using cache ---\u0026gt; dd3f294d79e3 Step 9/15 : COPY . ./Mlos.Python ---\u0026gt; Using cache ---\u0026gt; 33fb9dad43b5 Step 10/15 : ENV ACCEPT_EULA=Y ---\u0026gt; Using cache ---\u0026gt; 4f19a90fbef2 Step 11/15 : ARG SA_PASSWORD=DEFAULT_SA_PASSWORD ---\u0026gt; Using cache ---\u0026gt; 154868f57d1a Step 12/15 : RUN (/opt/mssql/bin/sqlservr --accept-eula \u0026amp; ) | grep -q \u0026quot;Service Broker manager has started\u0026quot; \u0026amp;\u0026amp; /opt/mssql-tools/bin/sqlcmd -S127.0.0.1 -Usa -P${SA_PASSWORD} -i ./Mlos.Python/MlosOptimizationServices/ModelsDatabase/SQLScripts/Schema.sql ---\u0026gt; Using cache ---\u0026gt; 48d1a8c19169 Step 13/15 : EXPOSE 1433 ---\u0026gt; Using cache ---\u0026gt; 63fd96771c97 Step 14/15 : ENV SA_PASSWORD=$SA_PASSWORD ---\u0026gt; Using cache ---\u0026gt; 94ec12721485 Step 15/15 : CMD /opt/mssql/bin/sqlservr \u0026amp; cd Mlos.Python; python3.7 start_mlos_optimization_runtime.py launch --database-connection-string-file ./Secrets/local_docker_connection_string.json ---\u0026gt; Using cache ---\u0026gt; 47630835a8d0 Successfully built 47630835a8d0 Successfully tagged mssql-server-linux-with-mlos-python:latest SECURITY WARNING: You are building a Docker image from Windows against a non-Windows Docker host. All files and directories added to build context will have '-rwxr-xr-x' permissions. It is recommended to double check and reset permissions for sensitive files and directories.  Run Docker container run_docker_container() docker run --detach -p1433:1433 --name MlosOptimizerService mssql-server-linux-with-mlos-python bb2ea175d37a4428e885e17bae73e90c784514b779aad27fc0a4b850ea1a3f47  Launch Mlos.Agent.Server We need to launch Mlos.Agent.Server and let it communicate with the Optimizer.\nprint(mlos_agent_server_exe_path, f\u0026#39;\u0026#34;{secrets_file_path}\u0026#34;\u0026#39;) mlos_agent_server_process = subprocess.Popen([mlos_agent_server_exe_path, secrets_file_path], creationflags=subprocess.CREATE_NEW_CONSOLE) time.sleep(15) # TODO: wait for Mlos.Agent.Server to signal readiness instead of blindly waiting. c:\\Users\\bpkroth\\src\\MLOS\\MLOS.msdata.2\\out\\dotnet\\source\\Mlos.Agent.Server\\obj\\AnyCPU\\Mlos.Agent.Server.exe \u0026quot;c:\\Users\\bpkroth\\src\\MLOS\\MLOS.msdata.2\\source\\Mlos.Python\\Secrets\\local_docker_connection_string.json\u0026quot;  Launch SmartCache microbenchmark print(smart_cache_exe_path) smart_cache_process = subprocess.Popen([smart_cache_exe_path], creationflags=subprocess.CREATE_NEW_CONSOLE) # wait for the process to exit # while smart_cache_process.poll() is None: time.sleep(1) print(\u0026#34;SmartCache.exe exited.\u0026#34;) c:\\Users\\bpkroth\\src\\MLOS\\MLOS.msdata.2\\out\\dotnet\\source\\Examples\\SmartCache\\obj\\x64\\SmartCache.exe SmartCache.exe exited.  Clean up Docker stop_docker_container() remove_docker_container() docker stop MlosOptimizerService MlosOptimizerService docker container rm MlosOptimizerService MlosOptimizerService  Download SmartCacheCppDocker.ipynb notebook "});index.add({'id':14,'href':'/MLOS/notebooks/SmartCacheOptimization/','title':"Smart Cache Optimization",'section':"Notebooks",'content':"Download SmartCacheOptimization.ipynb notebook Optimizing Smart Cache with Bayesian Optimization The goal of this notebook is to optimize SmartCache using Bayesian Optimization approach.\nWe\u0026rsquo;re using a sequential model-based optimization approach, that consists of the following loop:\n Get suggested config from optimizer, Apply suggested config to SmartCache, Execute a fixed workload, Collect the metrics from SmartCache, Register an observation with the optimizer.  # import the required classes and tools import grpc import pandas as pd from mlos.Grpc.BayesianOptimizerFactory import BayesianOptimizerFactory from mlos.Logger import create_logger from mlos.Examples.SmartCache import HitRateMonitor, SmartCache, SmartCacheWorkloadGenerator, SmartCacheWorkloadLauncher from mlos.Mlos.SDK import MlosExperiment from mlos.Optimizers.OptimizationProblem import OptimizationProblem, Objective from mlos.Spaces import Point, SimpleHypergrid, ContinuousDimension # The optimizer will be in a remote process via grpc, we pick the port here: grpc_port = 50051 Launch the optimizer service in a different process:\nimport subprocess optimizer_microservice = subprocess.Popen(f\u0026#34;start_optimizer_microservice launch --port {grpc_port}\u0026#34;, shell=True) Now the optimizer service that runs the surrogate model and suggests new points is started in the background. Next, we instantiate an object that connects to it over grpc using the BayesianOptimizerFactory.\nlogger = create_logger(\u0026#39;Optimizing Smart Cache\u0026#39;) optimizer_service_grpc_channel = grpc.insecure_channel(f\u0026#39;localhost:{grpc_port}\u0026#39;) bayesian_optimizer_factory = BayesianOptimizerFactory(grpc_channel=optimizer_service_grpc_channel, logger=logger) The optimization problem Then we can instantiate our optimization problem. We want to optimize the configuration of the SmartCache component that contains two implementations: an LRU (least recently used) cache and an MRU cache (most recently used). The SmartCache component has two parameters that we can adjust, the type of cache and the cache size. We are using some synthetic workloads for the cache and try to find what the optimum configuration for each workload is.\nHere, we measure \u0026lsquo;optimum\u0026rsquo; by the number of cache hits. Another option would be to measure runtime; however, this is a toy example with a trivial workload and there is likely substantial runtime difference. The parameter search space is declared in SmartCache.parameter_search_space:\nSmartCache.parameter_search_space smart_cache_config implementation: [LRU, MRU] lru_cache_config.cache_size: {1, 1 + 1, ... , 4096} mru_cache_config.cache_size: {1, 1 + 1, ... , 4096}  The optimization problem is constructed using this parameter space as the input to optimize, and defines a single continuous objective, \u0026lsquo;hit_rate\u0026rsquo; between 0 and 1.\n# Optimization Problem # optimization_problem = OptimizationProblem( parameter_space=SmartCache.parameter_search_space, objective_space=SimpleHypergrid(name=\u0026#34;objectives\u0026#34;, dimensions=[ContinuousDimension(name=\u0026#34;hit_rate\u0026#34;, min=0, max=1)]), objectives=[Objective(name=\u0026#34;hit_rate\u0026#34;, minimize=False)] ) # create an optimizer proxy that connects to the remote optimizer via grpc: optimizer = bayesian_optimizer_factory.create_remote_optimizer(optimization_problem=optimization_problem) Defining workloads Now we can instantiate our workloads and stand up the MLOS infrastructure, both of which are orchestrated bySmartCacheWorkloadLauncher. The MLOS infrastructure consists of the MlosAgent and a communication channel, which are available to both the SmartCacheWorkloadGenerator and the SmartCache. The SmartCacheWorkloadLauncher launches workloads in SmartCacheWorkloadGenerator in a separate thread, which will actually generate and run the workloads for the smart cache. The SmartCacheWorkloadLauncher also connects the SmartCacheWorkLloadGenerator to the optimization problem via a MlosAgent that will consume the configurations.\nworkload_launcher = SmartCacheWorkloadLauncher(logger=logger) mlos_agent = workload_launcher.mlos_agent 09/01/2020 19:47:14 - Optimizing Smart Cache - INFO - [ MlosAgent.py: 174 - _process_callbacks() ] Starting processing telemetry messages.  We set up the agent to consume configurations for the SmartCacheWorkloadGenerator, and we configure the workload to be sequential keys from a range from 0 to 2048.\nmlos_agent.set_configuration( component_type=SmartCacheWorkloadGenerator, new_config_values=Point( workload_type=\u0026#39;sequential_key_from_range\u0026#39;, sequential_key_from_range_config=Point( min=0, range_width=2048 ) ) ) Launching the experiment (measurement) Now we build the experiment, which collects hit-rate statistics from the SmartCacheWorkloadGenerator via the HitRateMonitor. This architecture reflects the native architecture for the C++ interface in which communication is done via shared memory between MLOS and the worker.\nhit_rate_monitor = HitRateMonitor() smart_cache_experiment = MlosExperiment( smart_component_types=[SmartCache], telemetry_aggregators=[hit_rate_monitor] ) mlos_agent.start_experiment(smart_cache_experiment) 09/01/2020 19:47:14 - Optimizing Smart Cache - INFO - [ExperimentManager.py: 41 - start_experiment() ] Starting experiment 1  Performing the optimization Now that we have all the pieces in place, we can iterate our main optimization loop. Our workload will run in the same process as this notebook, but in a separate thread, which we block on. In a real example, the workload might run completely independent of our optimization procedure.\nWe run the optimization for 20 iterations, in each of which we obtain a new configuration from the optimizer (that interfaces the remote optimizer service). The configuration is passed to SmartCacheWorkloadGenerator via the MlosAgent, after which we start a blocking workload for 0.2 seconds. Then, the hit-rate (our objective) is read from the HitRateMonitor and the suggested configuration together with the resulting hit-rate are passed to the optimizer.\nnum_iterations = 100 data = [] for i in range(num_iterations): # suggest runs a \u0026#39;cheap\u0026#39; search on the surrogate model to find a good candidate configuration new_config_values = optimizer.suggest() # set_configuration communicates the proposed configuration to the SmartCache mlos_agent.set_configuration(component_type=SmartCache, new_config_values=new_config_values) hit_rate_monitor.reset() # start_workload will actually run the worker, here for 0.2 seconds workload_launcher.start_workload(duration_s=0.2, block=True) # obtain hit-rate as quality measure for configuration hit_rate = hit_rate_monitor.get_hit_rate() objectives_df = pd.DataFrame({\u0026#39;hit_rate\u0026#39;: [hit_rate]}) # pass configuration and observed hit-rate to the optimizer to update the surrogate model features_df = new_config_values.to_dataframe() optimizer.register(features_df, objectives_df) data.append((features_df, objectives_df)) print(f\u0026#34;[{i+1}/{num_iterations}]current_config: {new_config_values}, hit_rate: {hit_rate}, num_requests: {hit_rate_monitor.num_requests}\u0026#34;) 09/01/2020 19:47:14 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:14 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 746} {'implementation': 'LRU', 'lru_cache_config.cache_size': 746} 09/01/2020 19:47:14 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:14 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:14 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 657} [1/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 746}, hit_rate: 5.271481283462582e-10, num_requests: 1934 {'implementation': 'MRU', 'mru_cache_config.cache_size': 657} 09/01/2020 19:47:15 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:15 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:15 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 3441} [2/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 657}, hit_rate: 0.2822025565829522, num_requests: 17018 {'implementation': 'MRU', 'mru_cache_config.cache_size': 3441} 09/01/2020 19:47:15 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:15 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:15 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 1789} [3/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 3441}, hit_rate: 0.9268571428597551, num_requests: 28000 {'implementation': 'LRU', 'lru_cache_config.cache_size': 1789} 09/01/2020 19:47:15 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:15 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:15 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 2220} [4/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 1789}, hit_rate: 0.5756279070556971, num_requests: 5375 {'implementation': 'LRU', 'lru_cache_config.cache_size': 2220} 09/01/2020 19:47:15 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:15 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:15 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 1878} [5/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 2220}, hit_rate: 0.9432120674372446, num_requests: 40584 {'implementation': 'MRU', 'mru_cache_config.cache_size': 1878} 09/01/2020 19:47:16 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:16 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:16 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 2122} [6/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 1878}, hit_rate: 0.8582813469687337, num_requests: 30617 {'implementation': 'LRU', 'lru_cache_config.cache_size': 2122} 09/01/2020 19:47:16 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:16 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:16 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 1461} [7/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 2122}, hit_rate: 0.9445257056193584, num_requests: 36918 {'implementation': 'LRU', 'lru_cache_config.cache_size': 1461} 09/01/2020 19:47:16 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:16 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:16 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 3869} [8/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 1461}, hit_rate: 0.506038086505797, num_requests: 4306 {'implementation': 'LRU', 'lru_cache_config.cache_size': 3869} 09/01/2020 19:47:16 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:16 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:16 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 206} [9/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 3869}, hit_rate: 0.9418330540503328, num_requests: 35209 {'implementation': 'MRU', 'mru_cache_config.cache_size': 206} 09/01/2020 19:47:16 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:17 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:17 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 2316.0} [10/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 206}, hit_rate: 0.09742317768379337, num_requests: 15351 {'implementation': 'LRU', 'lru_cache_config.cache_size': 2316.0} 09/01/2020 19:47:17 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:17 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:17 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 3192} [11/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 2316.0}, hit_rate: 0.9460413647754962, num_requests: 37955 {'implementation': 'LRU', 'lru_cache_config.cache_size': 3192} 09/01/2020 19:47:17 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:17 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:17 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 1853.0} [12/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 3192}, hit_rate: 0.9546079170186044, num_requests: 45118 {'implementation': 'MRU', 'mru_cache_config.cache_size': 1853.0} 09/01/2020 19:47:17 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:17 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:17 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 622} [13/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 1853.0}, hit_rate: 0.84980116243959, num_requests: 32690 {'implementation': 'MRU', 'mru_cache_config.cache_size': 622} 09/01/2020 19:47:17 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:17 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:17 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 3451} [14/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 622}, hit_rate: 0.2603409726620779, num_requests: 15084 {'implementation': 'LRU', 'lru_cache_config.cache_size': 3451} 09/01/2020 19:47:18 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:18 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:18 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 325} [15/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 3451}, hit_rate: 0.95191923934847, num_requests: 42595 {'implementation': 'MRU', 'mru_cache_config.cache_size': 325} 09/01/2020 19:47:18 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:18 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:18 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 3836.0} [16/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 325}, hit_rate: 0.1391437309466817, num_requests: 15056 {'implementation': 'LRU', 'lru_cache_config.cache_size': 3836.0} 09/01/2020 19:47:18 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:18 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:18 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 1175.0} [17/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 3836.0}, hit_rate: 0.9425090531414393, num_requests: 35623 {'implementation': 'MRU', 'mru_cache_config.cache_size': 1175.0} 09/01/2020 19:47:18 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:18 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:18 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 1783} [18/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 1175.0}, hit_rate: 0.525867861163455, num_requests: 22365 {'implementation': 'MRU', 'mru_cache_config.cache_size': 1783} 09/01/2020 19:47:19 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:19 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:19 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 1342.0} [19/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 1783}, hit_rate: 0.8153207621224445, num_requests: 30599 {'implementation': 'LRU', 'lru_cache_config.cache_size': 1342.0} 09/01/2020 19:47:19 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:19 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:19 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 3505} [20/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 1342.0}, hit_rate: 4.916420843207266e-10, num_requests: 2034 {'implementation': 'MRU', 'mru_cache_config.cache_size': 3505} 09/01/2020 19:47:19 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:19 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:19 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 726.0} [21/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 3505}, hit_rate: 0.9405325357896416, num_requests: 34439 {'implementation': 'LRU', 'lru_cache_config.cache_size': 726.0} 09/01/2020 19:47:19 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:19 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:19 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 1978.0} [22/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 726.0}, hit_rate: 4.967709883274858e-10, num_requests: 2013 {'implementation': 'LRU', 'lru_cache_config.cache_size': 1978.0} 09/01/2020 19:47:20 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:20 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:20 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 1647} [23/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 1978.0}, hit_rate: 4.098360654058049e-10, num_requests: 2458 {'implementation': 'MRU', 'mru_cache_config.cache_size': 1647} 09/01/2020 19:47:20 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:20 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:20 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 788} [24/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 1647}, hit_rate: 0.7522519448699245, num_requests: 29308 {'implementation': 'MRU', 'mru_cache_config.cache_size': 788} 09/01/2020 19:47:20 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:20 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:20 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 816} [25/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 788}, hit_rate: 0.35268721982882123, num_requests: 18067 {'implementation': 'LRU', 'lru_cache_config.cache_size': 816} 09/01/2020 19:47:20 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:20 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:20 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 3397.0} [26/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 816}, hit_rate: 5.249343829265435e-10, num_requests: 1978 {'implementation': 'LRU', 'lru_cache_config.cache_size': 3397.0} 09/01/2020 19:47:21 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:21 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:21 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 2258.0} [27/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 3397.0}, hit_rate: 0.948735919901158, num_requests: 43297 {'implementation': 'LRU', 'lru_cache_config.cache_size': 2258.0} 09/01/2020 19:47:21 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:21 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:21 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 4066.0} [28/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 2258.0}, hit_rate: 0.9436107822367463, num_requests: 36319 {'implementation': 'LRU', 'lru_cache_config.cache_size': 4066.0} 09/01/2020 19:47:21 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:22 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:22 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 2907.0} [29/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 4066.0}, hit_rate: 0.952536559365164, num_requests: 43149 {'implementation': 'MRU', 'mru_cache_config.cache_size': 2907.0} 09/01/2020 19:47:22 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:22 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:22 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 821.0} [30/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 2907.0}, hit_rate: 0.9359299233556725, num_requests: 34513 {'implementation': 'LRU', 'lru_cache_config.cache_size': 821.0} 09/01/2020 19:47:22 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:22 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:22 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 1527} [31/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 821.0}, hit_rate: 5.146680388498878e-10, num_requests: 1943 {'implementation': 'MRU', 'mru_cache_config.cache_size': 1527} 09/01/2020 19:47:22 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:22 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:22 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 2122} [32/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 1527}, hit_rate: 0.7032258064621331, num_requests: 28210 {'implementation': 'MRU', 'mru_cache_config.cache_size': 2122} 09/01/2020 19:47:23 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:23 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:23 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 2865} [33/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 2122}, hit_rate: 0.9527108155548002, num_requests: 43309 {'implementation': 'LRU', 'lru_cache_config.cache_size': 2865} 09/01/2020 19:47:23 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:23 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:23 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 2721} [34/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 2865}, hit_rate: 0.9214573346147092, num_requests: 29234 {'implementation': 'MRU', 'mru_cache_config.cache_size': 2721} 09/01/2020 19:47:23 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. [35/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 2721}, hit_rate: 0.9538676397721794, num_requests: 44394 {'implementation': 'MRU', 'mru_cache_config.cache_size': 4092.0} 09/01/2020 19:47:23 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:23 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 4092.0} 09/01/2020 19:47:24 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. [36/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 4092.0}, hit_rate: 0.9397434388625473, num_requests: 35466 {'implementation': 'MRU', 'mru_cache_config.cache_size': 3113.0} 09/01/2020 19:47:24 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:24 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 3113.0} 09/01/2020 19:47:24 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:24 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:24 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 3359.0} [37/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 3113.0}, hit_rate: 0.9513273284703917, num_requests: 42077 {'implementation': 'MRU', 'mru_cache_config.cache_size': 3359.0} 09/01/2020 19:47:24 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:24 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:24 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 1648} [38/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 3359.0}, hit_rate: 0.9438581101471022, num_requests: 36479 {'implementation': 'MRU', 'mru_cache_config.cache_size': 1648} 09/01/2020 19:47:25 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:25 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:25 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 3319} [39/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 1648}, hit_rate: 0.7537264644431967, num_requests: 30592 {'implementation': 'LRU', 'lru_cache_config.cache_size': 3319} 09/01/2020 19:47:25 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. [40/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 3319}, hit_rate: 0.9336894932836752, num_requests: 33000 {'implementation': 'MRU', 'mru_cache_config.cache_size': 2377.0} 09/01/2020 19:47:25 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:25 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 2377.0} 09/01/2020 19:47:25 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:25 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:25 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 1755} [41/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 2377.0}, hit_rate: 0.9438965592827115, num_requests: 42480 {'implementation': 'MRU', 'mru_cache_config.cache_size': 1755} 09/01/2020 19:47:25 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:26 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:26 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 2776.0} [42/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 1755}, hit_rate: 0.7990247426476783, num_requests: 27685 {'implementation': 'MRU', 'mru_cache_config.cache_size': 2776.0} 09/01/2020 19:47:26 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. [43/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 2776.0}, hit_rate: 0.9524825986089911, num_requests: 43100 {'implementation': 'MRU', 'mru_cache_config.cache_size': 3037.0} 09/01/2020 19:47:26 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:26 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 3037.0} 09/01/2020 19:47:26 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:26 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:26 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 2985.0} [44/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 3037.0}, hit_rate: 0.9434847397774854, num_requests: 36238 {'implementation': 'MRU', 'mru_cache_config.cache_size': 2985.0} 09/01/2020 19:47:27 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:27 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:27 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 1382} [45/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 2985.0}, hit_rate: 0.9492730290057891, num_requests: 40373 {'implementation': 'MRU', 'mru_cache_config.cache_size': 1382} 09/01/2020 19:47:27 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:27 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:27 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 2982.0} [46/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 1382}, hit_rate: 0.634035903204278, num_requests: 25254 {'implementation': 'MRU', 'mru_cache_config.cache_size': 2982.0} 09/01/2020 19:47:27 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:27 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:27 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 2599} [47/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 2982.0}, hit_rate: 0.9392086437727684, num_requests: 33689 {'implementation': 'LRU', 'lru_cache_config.cache_size': 2599} 09/01/2020 19:47:27 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:27 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:27 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 3706} [48/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 2599}, hit_rate: 0.9533644540600396, num_requests: 43915 {'implementation': 'MRU', 'mru_cache_config.cache_size': 3706} 09/01/2020 19:47:28 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:28 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:28 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 3199.0} [49/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 3706}, hit_rate: 0.9467290935115951, num_requests: 38445 {'implementation': 'MRU', 'mru_cache_config.cache_size': 3199.0} 09/01/2020 19:47:28 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:28 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:28 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 2964.0} [50/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 3199.0}, hit_rate: 0.9532686822600509, num_requests: 43825 {'implementation': 'MRU', 'mru_cache_config.cache_size': 2964.0} 09/01/2020 19:47:28 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. [51/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 2964.0}, hit_rate: 0.9342388337689291, num_requests: 34614 {'implementation': 'MRU', 'mru_cache_config.cache_size': 2669.0} 09/01/2020 19:47:29 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:29 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 2669.0} 09/01/2020 19:47:29 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:29 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:29 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 2802.0} [52/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 2669.0}, hit_rate: 0.9510563043697768, num_requests: 41844 {'implementation': 'MRU', 'mru_cache_config.cache_size': 2802.0} 09/01/2020 19:47:29 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:30 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:30 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 2957.0} [53/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 2802.0}, hit_rate: 0.9381810498373576, num_requests: 33129 {'implementation': 'MRU', 'mru_cache_config.cache_size': 2957.0} 09/01/2020 19:47:30 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:30 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:30 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 2748.0} [54/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 2957.0}, hit_rate: 0.952645209028102, num_requests: 43248 {'implementation': 'MRU', 'mru_cache_config.cache_size': 2748.0} 09/01/2020 19:47:30 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:30 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:30 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 2590.0} [55/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 2748.0}, hit_rate: 0.9317651762533563, num_requests: 35579 {'implementation': 'MRU', 'mru_cache_config.cache_size': 2590.0} 09/01/2020 19:47:31 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:31 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:31 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 3076.0} [56/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 2590.0}, hit_rate: 0.9517947510897542, num_requests: 42485 {'implementation': 'MRU', 'mru_cache_config.cache_size': 3076.0} 09/01/2020 19:47:31 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:31 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:31 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 3007.0} [57/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 3076.0}, hit_rate: 0.9397221568183506, num_requests: 36241 {'implementation': 'MRU', 'mru_cache_config.cache_size': 3007.0} 09/01/2020 19:47:31 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. [58/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 3007.0}, hit_rate: 0.9509261256092079, num_requests: 41733 {'implementation': 'MRU', 'mru_cache_config.cache_size': 2710.0} 09/01/2020 19:47:32 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:32 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 2710.0} 09/01/2020 19:47:32 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:32 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:32 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 3530} [59/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 2710.0}, hit_rate: 0.9380876084543641, num_requests: 36556 {'implementation': 'MRU', 'mru_cache_config.cache_size': 3530} 09/01/2020 19:47:32 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:32 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:32 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 2758.0} [60/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 3530}, hit_rate: 0.9540930691304113, num_requests: 44612 {'implementation': 'MRU', 'mru_cache_config.cache_size': 2758.0} 09/01/2020 19:47:32 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:33 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:33 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 2797.0} [61/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 2758.0}, hit_rate: 0.9454753600823866, num_requests: 37561 {'implementation': 'MRU', 'mru_cache_config.cache_size': 2797.0} 09/01/2020 19:47:33 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:33 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:33 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 1118} [62/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 2797.0}, hit_rate: 0.9522755342215116, num_requests: 42913 {'implementation': 'MRU', 'mru_cache_config.cache_size': 1118} 09/01/2020 19:47:33 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:33 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:33 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 2723.0} [63/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 1118}, hit_rate: 0.4987052415618044, num_requests: 22398 {'implementation': 'MRU', 'mru_cache_config.cache_size': 2723.0} 09/01/2020 19:47:33 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:34 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:34 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 3111.0} [64/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 2723.0}, hit_rate: 0.9406032482615835, num_requests: 34480 {'implementation': 'MRU', 'mru_cache_config.cache_size': 3111.0} 09/01/2020 19:47:34 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:34 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:34 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 605} 09/01/2020 19:47:34 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. [65/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 3111.0}, hit_rate: 0.9518819604353207, num_requests: 42563 {'implementation': 'LRU', 'lru_cache_config.cache_size': 605} 09/01/2020 19:47:34 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:34 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 2357} [66/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 605}, hit_rate: 4.5787545766580794e-10, num_requests: 2184 {'implementation': 'MRU', 'mru_cache_config.cache_size': 2357} 09/01/2020 19:47:34 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:34 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:34 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 337} [67/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 2357}, hit_rate: 0.9332290036537157, num_requests: 35991 {'implementation': 'LRU', 'lru_cache_config.cache_size': 337} 09/01/2020 19:47:35 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:35 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:35 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 141.0} [68/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 337}, hit_rate: 3.5536602688153305e-10, num_requests: 2924 {'implementation': 'LRU', 'lru_cache_config.cache_size': 141.0} 09/01/2020 19:47:35 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:35 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:35 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 1350.0} [69/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 141.0}, hit_rate: 2.0533880899274355e-10, num_requests: 4870 {'implementation': 'LRU', 'lru_cache_config.cache_size': 1350.0} 09/01/2020 19:47:35 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:35 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:35 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 1013.0} [70/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 1350.0}, hit_rate: 4.916420843207266e-10, num_requests: 2034 {'implementation': 'LRU', 'lru_cache_config.cache_size': 1013.0} 09/01/2020 19:47:36 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:36 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:36 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 1655} [71/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 1013.0}, hit_rate: 5.151983510998463e-10, num_requests: 1941 {'implementation': 'LRU', 'lru_cache_config.cache_size': 1655} 09/01/2020 19:47:36 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:36 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:36 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 1231.0} [72/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 1655}, hit_rate: 4.5372050796110687e-10, num_requests: 2222 {'implementation': 'LRU', 'lru_cache_config.cache_size': 1231.0} 09/01/2020 19:47:36 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:36 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:36 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 300.0} [73/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 1231.0}, hit_rate: 5.05050504795429e-10, num_requests: 2033 {'implementation': 'LRU', 'lru_cache_config.cache_size': 300.0} 09/01/2020 19:47:37 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:37 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:37 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 3492} [74/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 300.0}, hit_rate: 3.2981530332130103e-10, num_requests: 3082 {'implementation': 'MRU', 'mru_cache_config.cache_size': 3492} 09/01/2020 19:47:37 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:37 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:37 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 835.0} [75/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 3492}, hit_rate: 0.9420765336441984, num_requests: 35357 {'implementation': 'LRU', 'lru_cache_config.cache_size': 835.0} 09/01/2020 19:47:37 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:38 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:38 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 3199.0} [76/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 835.0}, hit_rate: 5.055611726463289e-10, num_requests: 1978 {'implementation': 'LRU', 'lru_cache_config.cache_size': 3199.0} 09/01/2020 19:47:38 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:38 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:38 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 3188.0} [77/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 3199.0}, hit_rate: 0.942504211118964, num_requests: 39520 {'implementation': 'LRU', 'lru_cache_config.cache_size': 3188.0} 09/01/2020 19:47:38 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:38 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:38 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 3335} [78/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 3188.0}, hit_rate: 0.9415775210400349, num_requests: 35055 {'implementation': 'MRU', 'mru_cache_config.cache_size': 3335} 09/01/2020 19:47:38 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:39 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:39 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 3215.0} [79/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 3335}, hit_rate: 0.9506315687987987, num_requests: 41484 {'implementation': 'LRU', 'lru_cache_config.cache_size': 3215.0} 09/01/2020 19:47:39 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:39 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:39 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 3203.0} [80/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 3215.0}, hit_rate: 0.9429001589220481, num_requests: 35867 {'implementation': 'LRU', 'lru_cache_config.cache_size': 3203.0} 09/01/2020 19:47:39 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:39 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:39 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 1799} [81/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 3203.0}, hit_rate: 0.9504212259138564, num_requests: 41308 {'implementation': 'MRU', 'mru_cache_config.cache_size': 1799} 09/01/2020 19:47:39 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:40 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:40 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 3179.0} [82/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 1799}, hit_rate: 0.8365851396111257, num_requests: 32341 {'implementation': 'LRU', 'lru_cache_config.cache_size': 3179.0} 09/01/2020 19:47:40 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:40 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:40 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 1225} [83/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 3179.0}, hit_rate: 0.9529065489341219, num_requests: 43488 {'implementation': 'MRU', 'mru_cache_config.cache_size': 1225} 09/01/2020 19:47:40 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:40 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:40 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 3803} [84/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 1225}, hit_rate: 0.5641036515728358, num_requests: 23579 {'implementation': 'MRU', 'mru_cache_config.cache_size': 3803} 09/01/2020 19:47:40 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:40 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:40 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 3179.0} [85/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 3803}, hit_rate: 0.9386569220649776, num_requests: 35940 {'implementation': 'LRU', 'lru_cache_config.cache_size': 3179.0} 09/01/2020 19:47:41 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:41 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:41 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 302} [86/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 3179.0}, hit_rate: 0.9511438727080526, num_requests: 41919 {'implementation': 'MRU', 'mru_cache_config.cache_size': 302} 09/01/2020 19:47:41 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:41 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:41 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 28} [87/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 302}, hit_rate: 0.14218233354867518, num_requests: 14819 {'implementation': 'MRU', 'mru_cache_config.cache_size': 28} 09/01/2020 19:47:41 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:41 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:41 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 3207.0} [88/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 28}, hit_rate: 0.011973392534222218, num_requests: 13530 {'implementation': 'LRU', 'lru_cache_config.cache_size': 3207.0} 09/01/2020 19:47:41 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:42 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:42 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 910} [89/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 3207.0}, hit_rate: 0.9524119341957336, num_requests: 43036 {'implementation': 'LRU', 'lru_cache_config.cache_size': 910} 09/01/2020 19:47:42 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:42 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:42 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 2638} [90/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 910}, hit_rate: 5.058168940284183e-10, num_requests: 1977 {'implementation': 'MRU', 'mru_cache_config.cache_size': 2638} 09/01/2020 19:47:42 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:42 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 [91/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 2638}, hit_rate: 0.9444790847739182, num_requests: 36887 {'implementation': 'LRU', 'lru_cache_config.cache_size': 3173.0} 09/01/2020 19:47:42 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 3173.0} 09/01/2020 19:47:42 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:43 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:43 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 3197.0} [92/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 3173.0}, hit_rate: 0.951562167404944, num_requests: 42281 {'implementation': 'LRU', 'lru_cache_config.cache_size': 3197.0} 09/01/2020 19:47:43 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:43 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:43 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 3205.0} [93/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 3197.0}, hit_rate: 0.9347355003207541, num_requests: 35569 {'implementation': 'LRU', 'lru_cache_config.cache_size': 3205.0} 09/01/2020 19:47:43 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:43 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:43 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 3127} [94/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 3205.0}, hit_rate: 0.9490052538545105, num_requests: 40161 {'implementation': 'MRU', 'mru_cache_config.cache_size': 3127} 09/01/2020 19:47:43 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:44 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:44 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 3203.0} [95/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 3127}, hit_rate: 0.9351570415420732, num_requests: 31584 {'implementation': 'LRU', 'lru_cache_config.cache_size': 3203.0} 09/01/2020 19:47:44 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:44 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:44 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 2318} [96/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 3203.0}, hit_rate: 0.9497176528369822, num_requests: 40730 {'implementation': 'MRU', 'mru_cache_config.cache_size': 2318} 09/01/2020 19:47:44 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:44 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:44 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 1090} [97/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 2318}, hit_rate: 0.9412422894866951, num_requests: 35515 {'implementation': 'MRU', 'mru_cache_config.cache_size': 1090} 09/01/2020 19:47:44 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:44 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:44 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;MRU\u0026quot;, \u0026quot;mru_cache_config.cache_size\u0026quot;: 932} [98/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 1090}, hit_rate: 0.48815120409248053, num_requests: 20846 {'implementation': 'MRU', 'mru_cache_config.cache_size': 932} 09/01/2020 19:47:44 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. 09/01/2020 19:47:45 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 65 - run() ] Started the SmartCacheWorkloadGenerator. Duration=0.2 09/01/2020 19:47:45 - Optimizing Smart Cache - INFO - [ SmartCache.py: 130 - reconfigure() ] Reconfiguring. New config values: {\u0026quot;implementation\u0026quot;: \u0026quot;LRU\u0026quot;, \u0026quot;lru_cache_config.cache_size\u0026quot;: 3181.0} [99/100]current_config: {'implementation': 'MRU', 'mru_cache_config.cache_size': 932}, hit_rate: 0.41828075082776156, num_requests: 20126 {'implementation': 'LRU', 'lru_cache_config.cache_size': 3181.0} 09/01/2020 19:47:45 - Optimizing Smart Cache - INFO - [SmartCacheWorkloadGenerator.py: 108 - run() ] Exiting the SmartCacheWorkloadGenerator. [100/100]current_config: {'implementation': 'LRU', 'lru_cache_config.cache_size': 3181.0}, hit_rate: 0.9479436734292119, num_requests: 40485  Analyzing results For a cyclical workload with 2048 keys, we assume that a MRU cache with a size of at least 2048 will perform best, and get 100% hits once the cache is filled. Now lets see the suggestions and results from the current experiment.\n# some pandas wrangling features, targets = zip(*data) data = pd.concat(features, ignore_index=True) data[\u0026#39;hit_rate\u0026#39;] = pd.concat(targets, ignore_index=True) data  implementation lru_cache_config.cache_size mru_cache_config.cache_size \\ 0 LRU 746.0 NaN 1 MRU NaN 657.0 2 MRU NaN 3441.0 3 LRU 1789.0 NaN 4 LRU 2220.0 NaN .. ... ... ... 95 LRU 3203.0 NaN 96 MRU NaN 2318.0 97 MRU NaN 1090.0 98 MRU NaN 932.0 99 LRU 3181.0 NaN hit_rate 0 5.271481e-10 1 2.822026e-01 2 9.268571e-01 3 5.756279e-01 4 9.432121e-01 .. ... 95 9.497177e-01 96 9.412423e-01 97 4.881512e-01 98 4.182808e-01 99 9.479437e-01 [100 rows x 4 columns]  # group by implementation, then plot lru_data, mru_data = data.groupby(\u0026#39;implementation\u0026#39;) import matplotlib.pyplot as plt line_lru = lru_data[1].plot(x=\u0026#39;lru_cache_config.cache_size\u0026#39;, y=\u0026#39;hit_rate\u0026#39;, label=\u0026#39;LRU\u0026#39;, marker=\u0026#39;o\u0026#39;, linestyle=\u0026#39;none\u0026#39;, alpha=.6) mru_data[1].plot(x=\u0026#39;mru_cache_config.cache_size\u0026#39;, y=\u0026#39;hit_rate\u0026#39;, label=\u0026#39;MRU\u0026#39;, marker=\u0026#39;o\u0026#39;, linestyle=\u0026#39;none\u0026#39;, alpha=.6, ax=plt.gca()) plt.ylabel(\u0026#34;Cache hitrate\u0026#34;) plt.xlabel(\u0026#34;Cache Size\u0026#34;) plt.legend() \u0026lt;matplotlib.legend.Legend at 0x20c92c3e490\u0026gt;  We can see that if the cache size is over 2048 keys, it means everything can fit into the cache and the strategy does not matter. However, for smaller cache sizes, the MRU strategy has an obvious advantage over the LRU strategy.\nGoing Further   Log how the optimum evolves over time. How many iterations are needed?\n  Can you adjust options in the Optimizer to improve convergence (see the BayesianOptimization notebook for suggestions).\n  Choose a different workload in the SmartCacheWorkloadGenerator. How do the workloads change the optimum strategy?\n  Clean up We need to stop all processes \u0026amp; separate threads after running the experiments:\n# Clean up # mlos_agent.stop_experiment(smart_cache_experiment) mlos_agent.stop_all() # Stop the optimizer service import signal optimizer_microservice.send_signal(signal.SIGTERM) 09/01/2020 19:47:46 - Optimizing Smart Cache - INFO - [ExperimentManager.py: 56 - stop_experiment() ] Stopped experiment 1 09/01/2020 19:47:46 - Optimizing Smart Cache - INFO - [ MlosAgent.py: 183 - _process_callbacks() ] Finished processing telemetry messages  Download SmartCacheOptimization.ipynb notebook "});index.add({'id':15,'href':'/MLOS/README/','title':"R E a D M E",'section':"",'content':"MLOS: Machine Learning Optimized Systems MLOS: An Infrastructure for Automated Software Performance Engineering  MLOS is an ML-powered infrastructure and methodology to democratize and automate Performance Engineering. MLOS enables continuous, instance-based, robust, and trackable systems optimization.\n From the MLOS paper at DEEM 2020\nOverview Problem All systems software (e.g. SqlServer, MySQL, LevelDB, OpenSSL, etc.) is full of parameter choices.\nSometimes these are encoded in the software as constants embedded in the code (e.g. choice of abstract data structure implementation, buffer limit size or alignment, etc.). Other times they may be exposed as configuration parameters either at startup or runtime.\nCareful selection of these parameters can yield dramatic performance differences for different contexts of a system (e.g. different workloads, hardware, etc.). Note that performance can be interpreted in different ways (e.g. reducing average/variability of latency/memory, increasing throughput, decreasing MTTR, etc.)\nGenerally speaking, this process is referred to as Software Performance Engineering, and typically involves a lot of manual effort that is brittle and not well tracked.\nGoals MLOS is about using machine-learning and data-science to optimize systems for a given context through these tunable choices.\nRoughly, this can happen in two modes:\n  Offline (e.g. at development time)\nIn this case, developers can use (micro)benchmarks to explore a parameter space for a component either interactively or with a background CI/CD pipeline and then interact with that data through a notebook experience to select the right value to check in to the code, along with the results of the experiments and analysis, all encoded in the notebook.\n  Online (e.g. at runtime)\nIn this case a system component provides hooks to adjust its parameters at runtime and exports data about its current state/performance. These can be combined with additional contextual information from the system to build a model (or simple heuristics) to invoke the hooks to adjust the component to improve performance at runtime.\n  Architecture To achieve this MLOS provides:\n  Code Annotations to help describe additional settings metadata for tunables (a.k.a. Settings).\nFor instance, metadata can include things like constraints on acceptable values a Setting can take on as well as developer intuition to help guide the automated search process.\nCurrently these are implemented as C# Attributes to provide reflection and easy cross-platform and cross-compiler support for C++ projects.\n  Code Generation tools to use that metadata to expose those settings to different target systems/languages (e.g. Python Notebooks, C++, C#, etc.)\nFor instance, we generate efficient messages over shared memory communication channels for\n  exporting data about the component using that Setting\nFor instance, this may include performance statistics, workload traces, etc.\n  receiving feedback (e.g. to change the Setting\u0026rsquo;s value)\nThis may involve a reconfiguration step or simply update a cache for the next instantiation to read.\n    An external agent (Mlos.Agent.Server) which can consume the information exported by the target system (e.g. SqlServer, MySQL, LevelDB, etc.) with mimimal impact on the target system.\nThe external agent can perform workload summarization, binning, cataloging, model inference, heuristic invocation, etc. based on the events exposed by the target system to then influence it.\nOnce hooks are created in the target system, iteration on the external agent can be more rapidly developed and deployed.\n  Python only installation Some of the examples require only the installation of the mlos Python library. These examples do not use the shared memory infrastructure.\nFirst, download the mlos code using git:\n$ git clone https://github.com/microsoft/MLOS.git For this simplified installation, it\u0026rsquo;s recommended to use the Anaconda python distribution. For a slimer installation experience, you can also use the miniconda installer. After installing either anaconda or miniconda, you can create a new environment with all requirements for the examples using\n$ conda env create -f MLOS/source/Mlos.Notebooks/environment.yml The environment will be called mlos_python_environment and you can activate it as follows:\n$ conda activate mlos_python_environment Use pip to install the Python library:\n$ pip install MLOS/source/Mlos.Python/ Alternatively, you can also install the package directly without checking out the code:\n$ pip install \u0026quot;git+https://github.com/microsoft/MLOS.git#egg=mlos\u0026amp;subdirectory=source/Mlos.Python\u0026quot; However, this does not include the examples and requires you to set up your environment manually.\nAfter this installation, you can run any of the Python-only example notebooks. To do so you can:\n$ python -m ipykernel install --user --name=mlos_environment $ jupyter-notebook --notebook-dir=MLOS/source/Mlos.Notebooks Jupyter will list a few notebooks. A good place to start is the BayesianOptimization.ipynb, which provides an Introduction to Bayesian Optimization.\nFull Build (C# and C++ components) MLOS supports Windows and Linux build environments.\nFor detailed instructions, please refer to:\n Prerequisites Build  Examples Code and documentation for examples of using MLOS to optimize a system are described in the Notebooks section. Additional code is in the source/Examples source directory. You can find the source of the notebooks on github as well.\nDocumentation   Additional overview documentation is available in the documentation tree.\n  Individual components may also include more detailed documentation in their respective subdirectories.\n  Contributing We welcome contributions! Please see Contributing and Code of Conduct for details.\nAlso, please see the Roadmap of planned features.\nContact For more formal enquiries, you can contact us.\nLicense  MIT License  "});})();